{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "`12`2`121`2`12`12112`12`12`12`12`12`12\n",
    "\n",
    "\n",
    "\n",
    "import importlib\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import time\n",
    "from abc import ABC, abstractmethod\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# LLM configuration\n",
    "LLM_API_ENDPOINT = os.getenv(\"OPENAI_API_BASE\", \"https://api.openai.com/v1\")\n",
    "LLM_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"YOUR_OPENAI_KEY_HERE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Connection successful!\n",
      "Response: Sure! A fun fact about Python programming is that the language is named after the British comedy television show \"Monty Python's Flying Circus.\" Its creator, Guido van Rossum, wanted a name that was short, unique, and slightly mysterious. This love for humor is reflected in Python's design, which emphasizes readability and simplicity, making it an enjoyable language for programmers to work with. Additionally, the Python standard library includes several modules and functions with playful names, further showcasing its lighthearted spirit!\n",
      "\n",
      "Usage: {'completion_tokens': 100, 'prompt_tokens': 20, 'total_tokens': 120, 'completion_tokens_details': CompletionTokensDetailsWrapper(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0, text_tokens=None), 'prompt_tokens_details': PromptTokensDetailsWrapper(audio_tokens=0, cached_tokens=0, text_tokens=None, image_tokens=None)}\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "# Initialize the language model\n",
    "lm = dspy.LM(\n",
    "    model=\"gpt-4o-mini\",                # Your model name\n",
    "    api_base=LLM_API_ENDPOINT,          # Your OpenAI-compatible endpoint\n",
    "    api_key=LLM_API_KEY,                # Your API key\n",
    "    temperature=0.7,\n",
    "    max_tokens=16384\n",
    ")\n",
    "\n",
    "# Configure DSPy to use this language model\n",
    "dspy.settings.configure(lm=lm)\n",
    "\n",
    "# Test the connection with a simple call\n",
    "try:\n",
    "    response = lm(\"Hello! Can you tell me a fun fact about Python programming?\")\n",
    "    print(\"✅ Connection successful!\")\n",
    "    print(\"Response:\", response[0])\n",
    "    \n",
    "    # Show usage statistics\n",
    "    if lm.history:\n",
    "        last_call = lm.history[-1]\n",
    "        print(f\"\\nUsage: {last_call['usage']}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(\"❌ Connection failed:\")\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing BEFORE optimization...\n",
      "=== ORIGINAL PROMPT (Before Optimization) ===\n",
      "[SYSTEM]: Your input fields are:\n",
      "1. `defender_field` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `trend_micro_field` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## defender_field ## ]]\n",
      "{defender_field}\n",
      "\n",
      "[[ ## trend_micro_field ## ]]\n",
      "{trend_micro_field}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Map Microsoft Defender fields to Trend Micro fields.\n",
      "----------------------------------------\n",
      "[USER]: [[ ## defender_field ## ]]\n",
      "CommandLine\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## trend_micro_field ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "================================================================================\n",
      "\n",
      "Result: Process Command Line\n",
      "\n",
      "=== OPTIMIZING PROMPT ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [00:00<00:00, 1313.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrapped 3 full traces after 4 examples for up to 1 rounds, amounting to 4 attempts.\n",
      "Optimization complete!\n",
      "\n",
      "Testing AFTER optimization...\n",
      "=== OPTIMIZED PROMPT (After Optimization) ===\n",
      "[SYSTEM]: Your input fields are:\n",
      "1. `defender_field` (str)\n",
      "\n",
      "Your output fields are:\n",
      "1. `trend_micro_field` (str)\n",
      "\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "[[ ## defender_field ## ]]\n",
      "{defender_field}\n",
      "\n",
      "[[ ## trend_micro_field ## ]]\n",
      "{trend_micro_field}\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "\n",
      "In adhering to this structure, your objective is: \n",
      "        Map Microsoft Defender fields to Trend Micro fields.\n",
      "----------------------------------------\n",
      "[USER]: [[ ## defender_field ## ]]\n",
      "SHA256\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## trend_micro_field ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "----------------------------------------\n",
      "[ASSISTANT]: [[ ## trend_micro_field ## ]]\n",
      "objectFileHashSha256\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "----------------------------------------\n",
      "[USER]: [[ ## defender_field ## ]]\n",
      "ProcessName\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## trend_micro_field ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "----------------------------------------\n",
      "[ASSISTANT]: [[ ## trend_micro_field ## ]]\n",
      "objectProcessName\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "----------------------------------------\n",
      "[USER]: [[ ## defender_field ## ]]\n",
      "MD5\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## trend_micro_field ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "----------------------------------------\n",
      "[ASSISTANT]: [[ ## trend_micro_field ## ]]\n",
      "objectFileHashMd5\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "----------------------------------------\n",
      "[USER]: [[ ## defender_field ## ]]\n",
      "FileName\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## trend_micro_field ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "----------------------------------------\n",
      "[ASSISTANT]: [[ ## trend_micro_field ## ]]\n",
      "objectFileName\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "----------------------------------------\n",
      "[USER]: [[ ## defender_field ## ]]\n",
      "IPAddress\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## trend_micro_field ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "----------------------------------------\n",
      "[ASSISTANT]: [[ ## trend_micro_field ## ]]\n",
      "objectIpAddress\n",
      "\n",
      "[[ ## completed ## ]]\n",
      "----------------------------------------\n",
      "[USER]: [[ ## defender_field ## ]]\n",
      "CommandLine\n",
      "\n",
      "Respond with the corresponding output fields, starting with the field `[[ ## trend_micro_field ## ]]`, and then ending with the marker for `[[ ## completed ## ]]`.\n",
      "================================================================================\n",
      "\n",
      "Result: objectCommandLine\n",
      "\n",
      "=== ANALYSIS ===\n",
      "BEFORE OPTIMIZATION:\n",
      "- Simple system message with field descriptions\n",
      "- Single user message with the input\n",
      "- No examples provided\n",
      "- Model relies on its base knowledge\n",
      "\n",
      "AFTER OPTIMIZATION:\n",
      "- Same system message structure\n",
      "- Multiple conversation examples (few-shot learning)\n",
      "- Shows input-output patterns from training data\n",
      "- Guides model with concrete examples\n",
      "- Uses special markers for structured output\n",
      "\n",
      "KEY INSIGHT:\n",
      "DSPy automatically selected the best examples from your training data\n",
      "and formatted them as a conversation to guide the model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "\n",
    "lm = dspy.LM(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_base=LLM_API_ENDPOINT,\n",
    "    api_key=LLM_API_KEY,\n",
    "    temperature=0.0,\n",
    "    max_tokens=16384\n",
    ")\n",
    "dspy.settings.configure(lm=lm)\n",
    "\n",
    "# 2. Define your task signature\n",
    "class FieldMapping(dspy.Signature):\n",
    "    \"\"\"Map Microsoft Defender fields to Trend Micro fields.\"\"\"\n",
    "    defender_field = dspy.InputField()\n",
    "    trend_micro_field = dspy.OutputField()\n",
    "\n",
    "# 3. Create predictor\n",
    "predictor = dspy.Predict(FieldMapping)\n",
    "\n",
    "# 4. Create your dataset\n",
    "trainset = [\n",
    "    dspy.Example(defender_field=\"SHA256\", trend_micro_field=\"objectFileHashSha256\").with_inputs('defender_field'),\n",
    "    dspy.Example(defender_field=\"ProcessName\", trend_micro_field=\"objectProcessName\").with_inputs('defender_field'),\n",
    "    dspy.Example(defender_field=\"IPAddress\", trend_micro_field=\"objectIpAddress\").with_inputs('defender_field'),\n",
    "    dspy.Example(defender_field=\"MD5\", trend_micro_field=\"objectFileHashMd5\").with_inputs('defender_field'),\n",
    "    dspy.Example(defender_field=\"FileName\", trend_micro_field=\"objectFileName\").with_inputs('defender_field')\n",
    "]\n",
    "\n",
    "# 5. Define evaluation metric\n",
    "def exact_match(example, pred, trace=None):\n",
    "    return example.trend_micro_field.lower() == pred.trend_micro_field.lower()\n",
    "\n",
    "def print_prompt_messages(messages, title):\n",
    "    \"\"\"Helper function to print messages in a readable format\"\"\"\n",
    "    print(f\"=== {title} ===\")\n",
    "    for i, msg in enumerate(messages):\n",
    "        role = msg['role'].upper()\n",
    "        content = msg['content']\n",
    "        print(f\"[{role}]: {content}\")\n",
    "        if i < len(messages) - 1:  # Don't print separator after last message\n",
    "            print(\"-\" * 40)\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "\n",
    "# 6. Test BEFORE optimization and capture prompt\n",
    "print(\"Testing BEFORE optimization...\")\n",
    "lm.history.clear()  # Clear history\n",
    "result_before = predictor(defender_field=\"CommandLine\")\n",
    "\n",
    "# Get the original prompt from history\n",
    "if lm.history:\n",
    "    original_messages = lm.history[-1]['messages']\n",
    "    print_prompt_messages(original_messages, \"ORIGINAL PROMPT (Before Optimization)\")\n",
    "    print(f\"Result: {result_before.trend_micro_field}\")\n",
    "    print()\n",
    "\n",
    "# 7. Optimize the prompt\n",
    "print(\"=== OPTIMIZING PROMPT ===\")\n",
    "optimizer = dspy.BootstrapFewShot(metric=exact_match, max_bootstrapped_demos=3)\n",
    "optimized_predictor = optimizer.compile(predictor, trainset=trainset)\n",
    "print(\"Optimization complete!\")\n",
    "print()\n",
    "\n",
    "# 8. Test AFTER optimization and capture prompt\n",
    "print(\"Testing AFTER optimization...\")\n",
    "lm.history.clear()  # Clear history to get clean optimized prompt\n",
    "result_after = optimized_predictor(defender_field=\"CommandLine\")\n",
    "\n",
    "# Get the optimized prompt from history\n",
    "if lm.history:\n",
    "    optimized_messages = lm.history[-1]['messages']\n",
    "    print_prompt_messages(optimized_messages, \"OPTIMIZED PROMPT (After Optimization)\")\n",
    "    print(f\"Result: {result_after.trend_micro_field}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
